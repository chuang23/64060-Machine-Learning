---
title: "R Notebook"
output: html_notebook
---
```{r}
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
library(dummies)
```

```{r}
Annie <- read.csv("UniversalBank.csv")
Annie<-Annie[,c(-1,-5)]
dummy_model <- dummyVars(~Education,data=Annie)
head(predict(dummy_model,Annie))
Loan_Dummy<- dummy.data.frame(Annie, names = c("Education"), sep= ".")

```

```{r}
norm_model<-preProcess(Loan_Dummy, method = c('range'))
Annie_normalized<-predict(norm_model,Loan_Dummy)
Annie_Predictors<-Annie_normalized[,-10]
Annie_labels<-Annie_normalized[,10]
set.seed(15)
Train_index = createDataPartition(Annie_normalized$Personal,p=0.6, list=FALSE) 
Train_Data = Annie_normalized[Train_index,]
Validation_Data = Annie_normalized[-Train_index,]
dim(Train_Data)
summary(Train_Data)
summary(Validation_Data)
```

```{r}
Train_Predictors<-Train_Data[,-10]
Validation_Predictors<-Validation_Data[,-10]

Train_labels <-Train_Data[,10] 
Validation_labels  <-Validation_Data[,10]

Train_labels=as.factor(Train_labels)
Validation_labels=as.factor(Validation_labels)
Annie_labels<-as.factor(Annie_labels)
```
```{r}
knn <- knn(Train_Predictors,Validation_Predictors,cl=Train_labels,k=1,prob = TRUE)
knn

x <- c(40, 10, 84, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1)
knn.1 <- knn(Train_Predictors, x, cl=Train_labels, k=1, prob = TRUE)
knn.1
```


```{r}
accuracy.df <- data.frame(k = seq(1, 14, 1), accuracy = rep(0, 14))

for(i in 1:14) {
                  knn <- knn(Train_Predictors, Validation_Predictors, cl = Train_labels, k = i)
                  accuracy.df[i, 2] <- confusionMatrix(knn, Validation_labels)$overall[1] 
                }
accuracy.df

which.max( (accuracy.df$accuracy) )
#3.	Show the confusion matrix for the validation data that results from using the best k.

knn.2 <- knn(Train_Predictors,Validation_Predictors,cl=Train_labels,k=3,prob = TRUE)
confusionMatrix(knn.2,Validation_labels)

```

```{r}
#4.	Consider the following customer: Classify the customer using the best k

knn.3 <- knn(Train_Predictors, x, cl=Train_labels, k=3, prob = TRUE)
knn.3

knn.4 <- knn(Annie_Predictors, x, cl=Annie_labels, k=3, prob = TRUE)
knn.4

#5.	Repartition the data, this time into training, validation, and test sets (50% : 30% : 20%)


set.seed(15)
Bank_Partition = createDataPartition(Annie_normalized$Personal,p=0.5, list=FALSE) 
Training_Data = Annie_normalized[Bank_Partition,]     #50% of total data assigned to Test data
Test_Validation_Data = Annie_normalized[-Bank_Partition,]

Test_Index = createDataPartition(Test_Validation_Data$Personal.Loan, p=0.6, list=FALSE) 
Validation_Data = Test_Validation_Data[Test_Index,]    #to achieve 50:30:20 ratio among the... 
#.......train, validation and testing, i partioned 60% test_valid_data to test and train
Test_Data = Test_Validation_Data[-Test_Index,] 


Training_Predictors<-Training_Data[,-10]
Test_Predictors<-Test_Data[,-10]
Validation_Predictors<-Validation_Data[,-10]


Training_labels <-Training_Data[,10]
Test_labels <-Test_Data[,10]
Validation_labels <-Validation_Data[,10]


Training_labels=as.factor(Training_labels)
Test_labels<-as.factor(Test_labels)
Validation_labels=as.factor(Validation_labels)

knn.5 <- knn(Training_Predictors, Test_Predictors , cl=Training_labels, k=3, prob = TRUE)
confusionMatrix(knn.5,Test_labels)
knn.6 <- knn(Validation_Predictors, Test_Predictors, cl=Validation_labels, k=3, prob = TRUE)
confusionMatrix(knn.6,Test_labels)

# Accuracy : for Training set, 0.959 for knn.pred5 i.e.
# Accuracy : for Validation set, 0.951 for knn.pred6 i.e.
#The Model performs more accuracy when we feed more data to the model. 
#In this HW, the training set has more data to be compared to validation set the more accurate we  could have.

```



